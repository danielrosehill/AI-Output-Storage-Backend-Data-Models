# AI Output Storage Backend - Data Models

A comprehensive data structure for storing and managing AI outputs, prompts, and related metadata in N8N workflows.

## ğŸ—ï¸ Architecture Overview

The data model is organized into three primary domains:

### 1. **OUTPUTS Domain** ğŸ“¤
Tables related to AI-generated content and their lifecycle management.

### 2. **INFERENCE Domain** ğŸ¤–  
Tables managing AI agents, assistants, models, and inference infrastructure.

### 3. **USERS Domain** ğŸ‘¥
Tables handling user interactions, prompts, sessions, and authentication.

---

## ğŸ“Š Data Model Diagrams

### **OUTPUTS Domain**
```mermaid
graph TD
    O[outputs] --> OT[output_tracking]
    O --> QA[quality_assessments]
    O --> BF[binary_file_data]
    O --> PII[pii_detection]
    
    QA --> QAT[qa_validation_taxonomy]
    O --> IS[information_sensitivity]
    IS --> ISP[information_sharing_policy]
    
    O --> RP[retention_policies]
    RP --> DRP[data_retention_policies]
    
    style O fill:#e1f5fe
    style QA fill:#f3e5f5
    style IS fill:#fff3e0
```

### **INFERENCE Domain**
```mermaid
graph TD
    AA[ai_assistants] --> SP[system_prompts]
    AA --> LLM[llm_models]
    AA --> STT[speech_to_text_models]
    
    AG[ai_agents] --> NW[n8n_workflows]
    
    API[api_usage] --> AP[api_parameters]
    API --> UI[ui_interfaces]
    
    MCP[mcp_usage]
    
    AA --> API
    AG --> API
    
    style AA fill:#e8f5e8
    style AG fill:#e8f5e8
    style LLM fill:#fff8e1
    style API fill:#fce4ec
```

### **USERS Domain**
```mermaid
graph TD
    U[users] --> S[sessions]
    S --> C[conversations]
    C --> P[prompts]
    P --> PT[prompt_tracking]
    
    U --> CR[credentials]
    P --> BF[binary_file_data]
    P --> PII[pii_detection]
    
    style U fill:#e3f2fd
    style S fill:#e3f2fd
    style C fill:#e3f2fd
    style P fill:#e1f5fe
```

### **Cross-Domain Relationships**
```mermaid
graph LR
    subgraph USERS
        U[users]
        P[prompts]
        S[sessions]
    end
    
    subgraph INFERENCE
        AA[ai_assistants]
        LLM[llm_models]
        API[api_usage]
    end
    
    subgraph OUTPUTS
        O[outputs]
        QA[quality_assessments]
        IS[information_sensitivity]
    end
    
    P --> O
    P --> API
    AA --> O
    LLM --> API
    O --> QA
    O --> IS
    
    style USERS fill:#e3f2fd,stroke:#1976d2
    style INFERENCE fill:#e8f5e8,stroke:#388e3c
    style OUTPUTS fill:#fff3e0,stroke:#f57c00
```

---

## ğŸ“ Directory Structure

```
â”œâ”€â”€ core-tables/           # Primary data storage
â”‚   â”œâ”€â”€ prompts.csv
â”‚   â”œâ”€â”€ outputs.csv
â”‚   â”œâ”€â”€ conversations.csv
â”‚   â””â”€â”€ binary_file_data.csv
â”œâ”€â”€ system-tables/         # AI system management
â”‚   â”œâ”€â”€ ai_assistants.csv
â”‚   â”œâ”€â”€ system_prompts.csv
â”‚   â”œâ”€â”€ ai_agents.csv
â”‚   â”œâ”€â”€ n8n_workflows.csv
â”‚   â”œâ”€â”€ users.csv
â”‚   â”œâ”€â”€ sessions.csv
â”‚   â””â”€â”€ credentials.csv
â”œâ”€â”€ tracking-tables/       # Quality & task management
â”‚   â”œâ”€â”€ output_tracking.csv
â”‚   â”œâ”€â”€ prompt_tracking.csv
â”‚   â””â”€â”€ quality_assessments.csv
â”œâ”€â”€ lookup-tables/         # Reference data
â”‚   â”œâ”€â”€ llm_models.csv
â”‚   â”œâ”€â”€ speech_to_text_models.csv
â”‚   â”œâ”€â”€ ui_interfaces.csv
â”‚   â”œâ”€â”€ api_parameters.csv
â”‚   â”œâ”€â”€ qa_validation_taxonomy.csv
â”‚   â”œâ”€â”€ retention_policies.csv
â”‚   â”œâ”€â”€ data_retention_policies.csv
â”‚   â”œâ”€â”€ api_usage.csv
â”‚   â””â”€â”€ mcp_usage.csv
â”œâ”€â”€ security-tables/       # Security & compliance
â”‚   â”œâ”€â”€ pii_detection.csv
â”‚   â”œâ”€â”€ information_sensitivity.csv
â”‚   â””â”€â”€ information_sharing_policy.csv
â””â”€â”€ docs/                  # Documentation
    â””â”€â”€ data-model-overview.md
```

---

## ğŸ”— Key Relationships

### **Primary Data Flow**
1. **User** creates **Session** â†’ **Conversation** â†’ **Prompt**
2. **Prompt** processed by **AI Assistant** using **LLM Model**
3. **AI Assistant** generates **Output** 
4. **Output** undergoes **Quality Assessment** and **Tracking**

### **Relational Fields**

#### **Core Relationships**
- `prompts.conversation_id` â†’ `conversations.id`
- `outputs.prompt_id` â†’ `prompts.id`
- `outputs.assistant_id` â†’ `ai_assistants.id`

#### **Security & Compliance**
- `pii_detection.prompt_id` â†’ `prompts.id`
- `pii_detection.output_id` â†’ `outputs.id`
- `information_sensitivity.id` â†’ `data_retention_policies.sensitivity_level_id`

#### **Quality Management**
- `quality_assessments.output_id` â†’ `outputs.id`
- `qa_validation_taxonomy.id` â†’ `quality_assessments.criteria_id`

#### **Usage Tracking**
- `api_usage.prompt_id` â†’ `prompts.id`
- `api_usage.output_id` â†’ `outputs.id`
- `api_usage.assistant_id` â†’ `ai_assistants.id`

---

## ğŸš€ N8N Integration Points

### **Webhook Endpoints**
- **Input Processing**: `POST /webhook/ai-prompt`
- **Output Storage**: `POST /webhook/ai-output`
- **Quality Review**: `POST /webhook/qa-review`

### **Workflow Triggers**
1. **Prompt Processing**: New prompt â†’ AI inference â†’ Output storage
2. **Quality Assessment**: New output â†’ QA validation â†’ Tracking update
3. **Retention Management**: Scheduled â†’ Policy evaluation â†’ Archive/Delete

### **Data Enrichment**
- **PII Detection**: Automated scanning on prompt/output creation
- **Sensitivity Classification**: Rule-based classification
- **Usage Tracking**: Real-time API call logging

---

## ğŸ“‹ Implementation Notes

### **Data Types & Formats**
- **Timestamps**: UTC ISO 8601 format
- **JSON Fields**: Flexible configuration storage
- **Boolean Fields**: Multi-modal delivery tracking
- **Scores**: 0-10 scale for quality metrics

### **Security Features**
- **Encryption**: Binary files and sensitive data
- **PII Masking**: Automatic detection and masking
- **Access Control**: Role-based data access
- **Audit Trails**: Complete change tracking

### **Performance Considerations**
- **Indexing**: Primary keys, foreign keys, timestamps
- **Partitioning**: Large tables by date/user
- **Archival**: Automated based on retention policies
- **Cleanup**: Scheduled deletion of expired data

---

## ğŸ”§ Getting Started

1. **Import CSV files** into your N8N database
2. **Configure workflows** using the provided webhook endpoints
3. **Set up retention policies** based on your requirements
4. **Enable PII detection** for compliance
5. **Configure quality assessment** workflows

For detailed implementation guidance, see [`docs/data-model-overview.md`](docs/data-model-overview.md).

---

## ğŸ“ˆ Monitoring & Analytics

The data model supports comprehensive analytics:
- **Usage Patterns**: API calls, model performance, user behavior
- **Quality Metrics**: Output quality trends, assessment scores
- **Cost Tracking**: Token usage, API costs per user/model
- **Compliance**: PII detection rates, retention policy adherence
